{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To show the performance of drop-in replacements for sklearn modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution time observed here will vary system to system <br> Performance may increase or decrease<br>\n",
    "Sytem used for execution of this notebook is : Ubuntu 16.04, 4GB RAM, 4 Cores, i5 Intel<br>\n",
    "Dask : 13 sec<br>\n",
    "Sklearn : 2 sec on 25 MB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch for RandomForestRegressor on 4 core using dask takes = 1309.43 sec= 21.82 min <br>\n",
    "GridSearch on using SKlearn takes = 1307.13 sec = 21.78min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop-in replacements for Sklearn from Dask to reduce the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dask\n",
    "lr = LinearRegression()\n",
    "lr.fit(datanew, target)\n",
    "\n",
    "#Sklearn\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(datanew, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.get_dummies(categorical_variables.categorize()).compute()\n",
    "# pd.get_dummies(categorical_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "a=time.time()\n",
    "# reading the csv files\n",
    "df=dd.read_csv('train.csv')\n",
    "test = dd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To distribute data on cluster among workers\n",
    "# #To use on other laptop in cluster\n",
    "# futures = df.map_partitions(lambda part: client.scatter([part])[0]).compute(scheduler='threads')  # single threaded local scheduler\n",
    "# df = dd.from_delayed(list(futures), meta=df.apply(lambda x: x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To distribute data on cluster among workers\n",
    "# #To use on other laptop in cluster\n",
    "# futures1 = test.map_partitions(lambda part: client.scatter([part])[0]).compute(scheduler='threads')  # single threaded local scheduler\n",
    "# test = dd.from_delayed(list(futures1), meta=test.apply(lambda x: x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            173638\n",
      "Product_Category_3            383247\n",
      "Purchase                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# finding the null values in the dataset\n",
    "print(df.isnull().sum().compute())\n",
    "\n",
    "#defining the data and the target\n",
    "categorical_variables = df[['Gender','Age','Occupation', 'City_Category','Stay_In_Current_City_Years','Marital_Status']]\n",
    "target = df['Purchase']\n",
    "\n",
    "#creating dummies for the categorical variables\n",
    "data = dd.get_dummies(categorical_variables.categorize()).compute()\n",
    "\n",
    "#converting dataframe to array\n",
    "datanew = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for execution\n",
      "8.761656999588013\n",
      "Predicted:\n",
      "[7911.62544111 9101.05308994 8972.23417733 ... 8939.70251971 9400.51898846\n",
      " 8514.05449281]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with joblib.parallel_backend('dask',scheduler_host='192.168.1.104:8786'):#To run on other laptop\n",
    "# with joblib.parallel_backend('dask'):#To run on same machine\n",
    "\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "a=time.time()\n",
    "lr = LinearRegression()\n",
    "lr.fit(datanew, target)\n",
    "print(\"Time taken for execution\")\n",
    "print(time.time()-a)\n",
    "\n",
    "# preparing the test data\n",
    "test_categorical = test[['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']]\n",
    "test_dummy = dd.get_dummies(test_categorical.categorize()).compute()\n",
    "testnew = test_dummy.values\n",
    "\n",
    "#predict on test and upload\n",
    "pred = lr.predict(testnew)\n",
    "print(\"Predicted:\")\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            173638\n",
      "Product_Category_3            383247\n",
      "Purchase                           0\n",
      "dtype: int64\n",
      "Time taken for execution:\n",
      "0.8812673091888428\n",
      "Predicted:\n",
      "[9228.  9948.  8556.5 ... 8675.  9039.5 8410.5]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "a=time.time()\n",
    "#reading the csv files\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "#finding the null values in the dataset\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#defining the data and the target\n",
    "categorical_variables = df[['Gender','Age','Occupation', 'City_Category','Stay_In_Current_City_Years','Marital_Status']]\n",
    "target = df['Purchase']\n",
    "\n",
    "#creating dummies for the categorical variables\n",
    "data = pd.get_dummies(categorical_variables)\n",
    "\n",
    "#converting dataframe to array\n",
    "datanew = data.values\n",
    "\n",
    "#fit the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "a=time.time()\n",
    "lr = LinearRegression()\n",
    "lr.fit(datanew, target)\n",
    "print(\"Time taken for execution:\")\n",
    "print(time.time()-a)\n",
    "\n",
    "\n",
    "#preparing the test data\n",
    "test_categorical = test[['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']]\n",
    "test_dummy = pd.get_dummies(test_categorical)\n",
    "testnew = test_dummy.values\n",
    "\n",
    "#predict on test and upload\n",
    "pred = lr.predict(testnew)\n",
    "print(\"Predicted:\")\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here sklearn takes less time for execution. This is due to overhead in doing partitoning and concatenating operation in dask.\n",
    "But if size of dataset is very large and not fit in memory then dask will take less time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# from dask.distributed import Client\n",
    "# client = Client(processes=False, threads_per_worker=1,\n",
    "#                 n_workers=4, memory_limit='4GB')\n",
    "# client = Client()\n",
    "\n",
    "# # client = Client('192.168.1.104:8786')\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'bootstrap': [True],\n",
    "'max_depth': [8, 9],\n",
    "'max_features': [2, 3],\n",
    "'min_samples_leaf': [4, 5],\n",
    "'min_samples_split': [8, 10],\n",
    "'n_estimators': [100, 200] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sklearn model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "import dask_searchcv as dcv\n",
    "grid_search = dcv.GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325.9793508052826\n"
     ]
    }
   ],
   "source": [
    "# with joblib.parallel_backend('dask',scheduler_host='192.168.1.104:8786'):#To run on other laptop\n",
    "# with joblib.parallel_backend('dask'):#To run on same machine\n",
    "#     grid_search.fit(df, target)\n",
    "a=time.time()\n",
    "grid_search.fit(data, target) #Run on same machine using all cores\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 9,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "'bootstrap': [True],\n",
    "'max_depth': [8, 9],\n",
    "'max_features': [2, 3],\n",
    "'min_samples_leaf': [4, 5],\n",
    "'min_samples_split': [8, 10],\n",
    "'n_estimators': [100, 200] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs=-1)\n",
    "a=time.time()\n",
    "grid_search.fit(data, target)\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
